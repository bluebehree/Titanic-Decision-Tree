# Titantic Decision Tree

This project was part of the first problem set of the Intro to Machine Learning class (CS M146) I took at UCLA.

## Summary and Findings

In this project, I created a baseline (Random Classifier) classifier that predicts a target class based on the distribution of classes in the training set, and compared the training and testing error of it to a Decision Tree classifier. From this, I easily saw how much more powerful and accurate a Decision Tree classifier is compared to a Random/Majority Classifier.

I explored the decision tree's vulnerability to overfitting training data by using cross-validation, testing the depth limits of the decision tree. It was clear that after a certain depth limit, the decision tree began to overfit, as evidenced by the increased testing error.

[Add comments about decision tree from the report later]
